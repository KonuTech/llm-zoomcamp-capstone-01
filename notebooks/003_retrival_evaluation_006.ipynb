{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "294cfe33-7ce4-4c46-8fdf-a304983ea5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/DataTalksClub/llm-zoomcamp/blob/main/03-vector-search/eval/evaluation-metrics.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "531840c5-b86a-4df9-be75-80ed49eaea93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84774894-d93d-475c-90a1-ebf83b26bbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables from .env\n",
    "load_dotenv(\"/home/jovyan/.envrc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8da8d673-67d9-43e1-9074-280906b77293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ec1ccc2-5297-4643-b1fd-aa189f1e67ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63eaaf8876374e659316b214f89ee245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9b9de964c64cb28967fadfe9ac1fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c3887c49914206bd50bff0b7a2c431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/11.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bdb2ae008814eca87f5ee943298e52f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b7661eb43724099bde73cada2b5c799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda94a35219f4caaa7236799b1f4cb12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a12dcdaae04ba5b5d136328920cb88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/383 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f98a7491e00433aa76b7199dc00b46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2b8464a8e84bba84a8ba81abb9cd27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6846e20c787543c89fe684476297916a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df52f131a0994b57913ee56754439354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'multi-qa-MiniLM-L6-cos-v1'\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c469b05d-aee1-4a80-93df-f060f6471ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Elasticsearch\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch, ConnectionError\n",
    "\n",
    "try:\n",
    "    es = Elasticsearch(['http://elasticsearch:9200'])  # Use the service name\n",
    "    if es.ping():\n",
    "        print(\"Connected to Elasticsearch\")\n",
    "    else:\n",
    "        print(\"Could not connect to Elasticsearch\")\n",
    "except ConnectionError as e:\n",
    "    print(f\"Connection error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a04036a7-5d2e-4151-8d31-c84e0b468b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Assuming final_results is defined as a list of dictionaries\n",
    "# Example: final_results = [{'recommendationid': 1, 'question': 'What is the best game?'}, ...]\n",
    "data_dir = os.path.abspath('../reviews-assistant/data/ground_truth')\n",
    "\n",
    "# Define the output file path\n",
    "output_file = os.path.join(data_dir, \"ground_truth_retrieval.json\")\n",
    "\n",
    "# Load the JSON file content\n",
    "with open(output_file, 'r', encoding='utf-8') as json_file:\n",
    "    ground_truth = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c79416e0-4dfb-4b5d-b75d-c8b89a7a7f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document_id': 8862,\n",
       " 'appid': '2208920',\n",
       " 'review': {'appid': '2208920',\n",
       "  'timestamp_query': 1727643597,\n",
       "  'title': \"Assassin's Creed Valhalla\",\n",
       "  'recommendationid': '174722275',\n",
       "  'author.steamid': '76561199291372999',\n",
       "  'author.playtimeforever': None,\n",
       "  'author.playtime_last_two_weeks': 0,\n",
       "  'author.playtime_at_review': 8996,\n",
       "  'author.last_played': 1726115935,\n",
       "  'language': 'english',\n",
       "  'review': 'The Graphics are amazing. I also enjoyed the story line. I never expected Eivor to be the leader eventually. I thought he was just the caretaker.',\n",
       "  'voted_up': True,\n",
       "  'votes_up': 0,\n",
       "  'timestamp_created': 1726050285,\n",
       "  'timestamp_updated': 1726050285},\n",
       " 'question': 'Does the character development meet expectations throughout the game?',\n",
       " 'answer': \"The character development, especially Eivor's role, is positively noted.\",\n",
       " 'section': 'characters'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth [-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3976ef8b-1a9f-49ef-8cc3-2bc319f898ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Elasticsearch!\n",
      "Index 'steam-reviews' created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 3654/8863 [03:36<05:02, 17.24it/s]"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch, NotFoundError, ConnectionError\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "\n",
    "class ReviewIndexer:\n",
    "    def __init__(self, es_host='http://elasticsearch:9200', index_name='steam-reviews', model=None):\n",
    "        self.es = Elasticsearch([es_host])\n",
    "        self.index_name = index_name\n",
    "        self.model = model  # Expecting a SentenceTransformer model to encode text\n",
    "        \n",
    "        # Check the connection upon initialization\n",
    "        self.check_connection()\n",
    "        \n",
    "        self.index_settings = {\n",
    "            \"settings\": {\n",
    "                \"number_of_shards\": 1,\n",
    "                \"number_of_replicas\": 0\n",
    "            },\n",
    "            \"mappings\": {\n",
    "                \"properties\": {\n",
    "                    \"appid\": {\"type\": \"keyword\"},\n",
    "                    \"timestamp_query\": {\"type\": \"integer\"},\n",
    "                    \"title\": {\"type\": \"keyword\"},\n",
    "                    \"author.steamid\": {\"type\": \"keyword\"},\n",
    "                    \"author.playtimeforever\": {\"type\": \"integer\"},\n",
    "                    \"author.playtime_last_two_weeks\": {\"type\": \"integer\"},\n",
    "                    \"author.playtime_at_review\": {\"type\": \"integer\"},\n",
    "                    \"author.last_played\": {\"type\": \"integer\"},\n",
    "                    \"language\": {\"type\": \"keyword\"},\n",
    "                    \"review\": {\"type\": \"text\"},\n",
    "                    \"voted_up\": {\"type\": \"boolean\"},\n",
    "                    \"votes_up\": {\"type\": \"integer\"},\n",
    "                    \"timestamp_created\": {\"type\": \"integer\"},\n",
    "                    \"timestamp_updated\": {\"type\": \"integer\"},\n",
    "                    \"question\": {\"type\": \"text\"},\n",
    "                    \"answer\": {\"type\": \"text\"},\n",
    "                    \"section\": {\"type\": \"keyword\"},\n",
    "                    \"question_vector\": {\n",
    "                        \"type\": \"dense_vector\",\n",
    "                        \"dims\": 384,\n",
    "                        \"index\": True,\n",
    "                        \"similarity\": \"cosine\"\n",
    "                    },\n",
    "                    \"answer_vector\": {\n",
    "                        \"type\": \"dense_vector\",\n",
    "                        \"dims\": 384,\n",
    "                        \"index\": True,\n",
    "                        \"similarity\": \"cosine\"\n",
    "                    },\n",
    "                    \"question_answer_vector\": {\n",
    "                        \"type\": \"dense_vector\",\n",
    "                        \"dims\": 384,\n",
    "                        \"index\": True,\n",
    "                        \"similarity\": \"cosine\"\n",
    "                    },\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Drop the index if it exists and create a new one\n",
    "        self.drop_and_create_index()\n",
    "\n",
    "    def check_connection(self):\n",
    "        \"\"\"Check if Elasticsearch connection is established.\"\"\"\n",
    "        try:\n",
    "            self.es.ping()\n",
    "            print(\"Connected to Elasticsearch!\")\n",
    "        except ConnectionError:\n",
    "            print(\"Failed to connect to Elasticsearch.\")\n",
    "\n",
    "    def drop_and_create_index(self):\n",
    "        \"\"\"Delete the existing index if it exists and create a new one.\"\"\"\n",
    "        try:\n",
    "            if self.es.indices.exists(index=self.index_name):\n",
    "                self.es.indices.delete(index=self.index_name)\n",
    "                print(f\"Index '{self.index_name}' deleted.\")\n",
    "            self.es.indices.create(index=self.index_name, body=self.index_settings)\n",
    "            print(f\"Index '{self.index_name}' created.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating index: {e}\")\n",
    "\n",
    "    def encode_vectors(self, question, answer):\n",
    "        \"\"\"Generate vectors for question, answer, and a combined question + answer.\"\"\"\n",
    "        question_vector = self.model.encode(question) if question else [0]*384\n",
    "        answer_vector = self.model.encode(answer) if answer else [0]*384\n",
    "        combined_text = f\"{question} {answer}\" if question and answer else \"\"\n",
    "        question_answer_vector = self.model.encode(combined_text) if combined_text else [0]*384\n",
    "        return question_vector, answer_vector, question_answer_vector\n",
    "\n",
    "    def prepare_document(self, review):\n",
    "        \"\"\"Prepare the document to be indexed.\"\"\"\n",
    "        question_vector, answer_vector, question_answer_vector = self.encode_vectors(review[\"question\"], review[\"answer\"])\n",
    "        \n",
    "        return {\n",
    "            \"appid\": review[\"appid\"],\n",
    "            \"timestamp_query\": review[\"review\"][\"timestamp_query\"],\n",
    "            \"title\": review[\"review\"][\"title\"],\n",
    "            \"author.steamid\": review[\"review\"][\"author.steamid\"],\n",
    "            \"author.playtimeforever\": review[\"review\"][\"author.playtimeforever\"],\n",
    "            \"author.playtime_last_two_weeks\": review[\"review\"][\"author.playtime_last_two_weeks\"],\n",
    "            \"author.playtime_at_review\": review[\"review\"][\"author.playtime_at_review\"],\n",
    "            \"author.last_played\": review[\"review\"][\"author.last_played\"],\n",
    "            \"language\": review[\"review\"][\"language\"],\n",
    "            \"review\": review[\"review\"][\"review\"],\n",
    "            \"voted_up\": review[\"review\"][\"voted_up\"],\n",
    "            \"votes_up\": review[\"review\"][\"votes_up\"],\n",
    "            \"timestamp_created\": review[\"review\"][\"timestamp_created\"],\n",
    "            \"timestamp_updated\": review[\"review\"][\"timestamp_updated\"],\n",
    "            \"question\": review[\"question\"],\n",
    "            \"answer\": review[\"answer\"],\n",
    "            \"section\": review[\"section\"],\n",
    "            \"question_vector\": question_vector,\n",
    "            \"answer_vector\": answer_vector,\n",
    "            \"question_answer_vector\": question_answer_vector\n",
    "        }\n",
    "\n",
    "    def index_reviews(self, reviews):\n",
    "        \"\"\"Index the provided reviews into Elasticsearch.\"\"\"\n",
    "        for review in tqdm(reviews):\n",
    "            # Prepare the document\n",
    "            doc = self.prepare_document(review)\n",
    "\n",
    "            # Index the document\n",
    "            try:\n",
    "                self.es.index(index=self.index_name, body=doc)\n",
    "            except Exception as e:\n",
    "                print(f\"Error indexing document with appid {review['appid']}: {e}\")\n",
    "\n",
    "    def load_reviews_from_file(self, file_path):\n",
    "        \"\"\"Load reviews from a JSON file.\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r') as file:\n",
    "                reviews = json.load(file)\n",
    "                return reviews\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading reviews from file: {e}\")\n",
    "            return []\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    import os\n",
    "\n",
    "    # Define the data directory and output file path\n",
    "    data_dir = os.path.abspath('../reviews-assistant/data/ground_truth')\n",
    "    output_file = os.path.join(data_dir, \"ground_truth_retrieval.json\")\n",
    "\n",
    "    # Initialize the model\n",
    "    model_name = 'multi-qa-MiniLM-L6-cos-v1'\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    # Load reviews from the specified JSON file\n",
    "    indexer = ReviewIndexer(model=model)\n",
    "    reviews = indexer.load_reviews_from_file(output_file)\n",
    "    \n",
    "    # Index the loaded reviews\n",
    "    if reviews:\n",
    "        indexer.index_reviews(reviews)\n",
    "    else:\n",
    "        print(\"No reviews found to index.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6295ebb1-092f-4a9b-aba4-5b590797e2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to check mappings in Elasticsearch\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "def check_index_mapping(es_host='http://elasticsearch:9200', index_name='steam-reviews'):\n",
    "    es = Elasticsearch([es_host])\n",
    "\n",
    "    try:\n",
    "        # Get the index mappings\n",
    "        response = es.indices.get_mapping(index=index_name)\n",
    "        mapping = response[index_name]['mappings']\n",
    "        \n",
    "        # Check for vector fields and their dimensions\n",
    "        vector_fields = [\"question_vector\", \"answer_vector\", \"question_answer_vector\"]\n",
    "        \n",
    "        for field in vector_fields:\n",
    "            if field in mapping['properties']:\n",
    "                dims = mapping['properties'][field]['dims']\n",
    "                print(f\"{field}: {dims} dimensions\")\n",
    "            else:\n",
    "                print(f\"{field} not found in index.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving index mapping: {e}\")\n",
    "\n",
    "# Run the check\n",
    "check_index_mapping()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768f592d-9138-4fa9-892a-655828c4d7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def check_vector_dimensions(query, model_name='multi-qa-MiniLM-L6-cos-v1'):\n",
    "    # Load the model\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    # Encode the query and get the vector\n",
    "    vector = model.encode(query)\n",
    "\n",
    "    # Check the dimensions of the vector\n",
    "    vector_dimensions = len(vector)\n",
    "    print(f\"Generated vector has {vector_dimensions} dimensions.\")\n",
    "\n",
    "# Example Usage\n",
    "query = 'Is God of War: Ragnarok a game for kids?'\n",
    "check_vector_dimensions(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74435912-3d88-4a8d-9303-9ba2746353ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "def verify_appid_exists(es_host='http://elasticsearch:9200', index_name='steam-reviews', appid='2322010'):\n",
    "    es = Elasticsearch([es_host])\n",
    "\n",
    "    try:\n",
    "        # Define a query to check if the appid exists\n",
    "        search_query = {\n",
    "            \"query\": {\n",
    "                \"term\": {\n",
    "                    \"appid\": appid  # Filter by appid\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Perform the search\n",
    "        es_results = es.search(index=index_name, body=search_query)\n",
    "\n",
    "        if es_results['hits']['total']['value'] > 0:\n",
    "            print(f\"AppID '{appid}' exists in the index.\")\n",
    "            for hit in es_results['hits']['hits']:\n",
    "                print(hit['_id'])\n",
    "        else:\n",
    "            print(f\"AppID '{appid}' not found in the index.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking for AppID: {e}\")\n",
    "\n",
    "# Run the check for appid 2322010 (God of War: Ragnarok)\n",
    "# verify_appid_exists(appid=\"552520\")\n",
    "verify_appid_exists(appid=\"2322010\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b5bd3b-0dd5-43c0-8200-9ebbcd48db45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "class ReviewReader:\n",
    "    def __init__(self, es_host='http://elasticsearch:9200', index_name='steam-reviews', model=None):\n",
    "        self.es = Elasticsearch([es_host])\n",
    "        self.index_name = index_name\n",
    "        self.model = model  # Ensure the model is passed for generating embeddings\n",
    "\n",
    "    def read_all_reviews(self):\n",
    "        \"\"\"Retrieve all reviews from the index.\"\"\"\n",
    "        try:\n",
    "            response = self.es.search(index=self.index_name, body={\"query\": {\"match_all\": {}}})\n",
    "            return response['hits']['hits']  # returns the list of documents\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving documents: {e}\")\n",
    "            return []\n",
    "\n",
    "    def read_review_by_appid(self, appid):\n",
    "        \"\"\"Retrieve a specific review by appid.\"\"\"\n",
    "        try:\n",
    "            response = self.es.search(index=self.index_name, body={\n",
    "                \"query\": {\n",
    "                    \"term\": {\n",
    "                        \"appid\": appid  # Search by appid\n",
    "                    }\n",
    "                }\n",
    "            })\n",
    "            return response['hits']['hits']  # returns the list of documents matching the appid\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving document with appid {appid}: {e}\")\n",
    "            return []\n",
    "\n",
    "    def read_reviews_knn(self, query, title, vector_field=\"answer_vector\", num_results=5):\n",
    "    # def read_reviews_knn(self, query, vector_field=\"answer_vector\", num_results=5):\n",
    "        \"\"\"Retrieve reviews using KNN search only to test vector querying.\"\"\"\n",
    "        try:\n",
    "            # Ensure the model is set\n",
    "            if self.model is None:\n",
    "                raise ValueError(\"Model for embedding generation is not initialized.\")\n",
    "\n",
    "            # Generate the embedding vector from the query\n",
    "            # knn_vector = self.model.encode(query).tolist()\n",
    "\n",
    "            # Define the KNN query\n",
    "            knn_query = {\n",
    "                \"field\": vector_field,  # Use the specified vector field (e.g., \"answer_vector\")\n",
    "                \"query_vector\": knn_vector,\n",
    "                \"k\": num_results,\n",
    "                \"num_candidates\": 10000,  # Adjust as necessary\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"title\": title  # Filter by title\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # Perform the search\n",
    "            es_results = self.es.search(index=self.index_name, body={\"knn\": knn_query})\n",
    "\n",
    "            result_docs = []\n",
    "\n",
    "            # Collect results\n",
    "            for hit in es_results['hits']['hits']:\n",
    "                result_docs.append(hit['_source'])  # Append only the source of each document\n",
    "\n",
    "            if not result_docs:\n",
    "                print(\"No results found.\")\n",
    "            return result_docs\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing KNN search: {e}\")\n",
    "            return []\n",
    "    \n",
    "\n",
    "    def read_reviews_knn_and_keyword(self, field, query, vector, title, num_results=5):\n",
    "    # def read_reviews_knn_and_keyword(self, field, query, vector, num_results=5):\n",
    "        \"\"\"Retrieve reviews using both KNN and keyword search in a single query.\"\"\"\n",
    "        try:\n",
    "            # Ensure the model is set\n",
    "            if self.model is None:\n",
    "                raise ValueError(\"Model for embedding generation is not initialized.\")\n",
    "\n",
    "            # Define the KNN query\n",
    "            knn_query = {\n",
    "                \"field\": field,  # Use the specified vector field (e.g., \"answer_vector\")\n",
    "                \"query_vector\": vector,\n",
    "                \"k\": num_results,\n",
    "                \"num_candidates\": 10000,  # Adjust as necessary\n",
    "                \"boost\": 0.5,\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"title\": title  # Filter by title\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # Define the keyword search query\n",
    "            keyword_query = {\n",
    "                \"bool\": {\n",
    "                    \"must\": {\n",
    "                        \"multi_match\": {\n",
    "                            \"query\": query,\n",
    "                            \"fields\": [\"question^3\", \"answer\", \"section\"],  # Relevant fields for keyword search\n",
    "                            \"type\": \"best_fields\",\n",
    "                            \"boost\": 0.5\n",
    "                        }\n",
    "                    },\n",
    "                    \"filter\": {\n",
    "                        \"term\": {\n",
    "                            \"title\": title  # Filter by title\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # Combine the KNN and keyword search queries\n",
    "            search_query = {\n",
    "                \"knn\": knn_query,\n",
    "                \"query\": keyword_query,\n",
    "                \"size\": num_results,  # Limit the number of results\n",
    "                \"_source\": [\"answer\", \"section\", \"question\", \"title\"]\n",
    "            }\n",
    "\n",
    "            # Perform the search\n",
    "            es_results = self.es.search(index=self.index_name, body=search_query)\n",
    "            result_docs = []\n",
    "\n",
    "            # Collect results\n",
    "            for hit in es_results['hits']['hits']:\n",
    "                result_docs.append(hit['_source'])  # Append only the source of each document\n",
    "\n",
    "            return result_docs\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing KNN and keyword search: {e}\")\n",
    "            return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0cda7a-b0a6-4fb3-a3b8-a351ba84947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "class ReviewReader:\n",
    "    def __init__(self, es_host='http://elasticsearch:9200', index_name='steam-reviews', model=None):\n",
    "        self.es = Elasticsearch([es_host])\n",
    "        self.index_name = index_name\n",
    "        self.model = model  # Ensure the model is passed for generating embeddings\n",
    "\n",
    "    def read_all_reviews(self):\n",
    "        \"\"\"Retrieve all reviews from the index.\"\"\"\n",
    "        try:\n",
    "            response = self.es.search(index=self.index_name, body={\"query\": {\"match_all\": {}}})\n",
    "            return response['hits']['hits']  # returns the list of documents\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving documents: {e}\")\n",
    "            return []\n",
    "\n",
    "    def read_review_by_appid(self, appid):\n",
    "        \"\"\"Retrieve a specific review by appid.\"\"\"\n",
    "        try:\n",
    "            response = self.es.search(index=self.index_name, body={\n",
    "                \"query\": {\n",
    "                    \"term\": {\n",
    "                        \"appid\": appid  # Search by appid\n",
    "                    }\n",
    "                }\n",
    "            })\n",
    "            return response['hits']['hits']  # returns the list of documents matching the appid\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving document with appid {appid}: {e}\")\n",
    "            return []\n",
    "\n",
    "    def read_reviews_knn(self, query, title, vector_field=\"answer_vector\", num_results=5):\n",
    "    # def read_reviews_knn(self, query, vector_field=\"answer_vector\", num_results=5):\n",
    "        \"\"\"Retrieve reviews using KNN search only to test vector querying.\"\"\"\n",
    "        try:\n",
    "            # Ensure the model is set\n",
    "            if self.model is None:\n",
    "                raise ValueError(\"Model for embedding generation is not initialized.\")\n",
    "\n",
    "            # Generate the embedding vector from the query\n",
    "            # knn_vector = self.model.encode(query).tolist()\n",
    "\n",
    "            # Define the KNN query\n",
    "            knn_query = {\n",
    "                \"field\": vector_field,  # Use the specified vector field (e.g., \"answer_vector\")\n",
    "                \"query_vector\": knn_vector,\n",
    "                \"k\": num_results,\n",
    "                \"num_candidates\": 10000,  # Adjust as necessary\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"title\": title  # Filter by title\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # Perform the search\n",
    "            es_results = self.es.search(index=self.index_name, body={\"knn\": knn_query})\n",
    "\n",
    "            result_docs = []\n",
    "\n",
    "            # Collect results\n",
    "            for hit in es_results['hits']['hits']:\n",
    "                result_docs.append(hit['_source'])  # Append only the source of each document\n",
    "\n",
    "            if not result_docs:\n",
    "                print(\"No results found.\")\n",
    "            return result_docs\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing KNN search: {e}\")\n",
    "            return []\n",
    "    \n",
    "\n",
    "    def read_reviews_knn_and_keyword(self, field, query, vector, title, num_results=5):\n",
    "    # def read_reviews_knn_and_keyword(self, field, query, vector, num_results=5):\n",
    "        \"\"\"Retrieve reviews using both KNN and keyword search in a single query.\"\"\"\n",
    "        try:\n",
    "            # Ensure the model is set\n",
    "            if self.model is None:\n",
    "                raise ValueError(\"Model for embedding generation is not initialized.\")\n",
    "\n",
    "            # Define the KNN query\n",
    "            knn_query = {\n",
    "                \"field\": field,  # Use the specified vector field (e.g., \"answer_vector\")\n",
    "                \"query_vector\": vector,\n",
    "                \"k\": num_results,\n",
    "                \"num_candidates\": 10000,  # Adjust as necessary\n",
    "                \"boost\": 0.5,\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"title\": title  # Filter by title\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # Define the keyword search query\n",
    "            keyword_query = {\n",
    "                \"bool\": {\n",
    "                    \"must\": {\n",
    "                        \"multi_match\": {\n",
    "                            \"query\": query,\n",
    "                            \"fields\": [\"question^3\", \"answer\", \"section\"],  # Relevant fields for keyword search\n",
    "                            \"type\": \"best_fields\",\n",
    "                            \"boost\": 0.5\n",
    "                        }\n",
    "                    },\n",
    "                    \"filter\": {\n",
    "                        \"term\": {\n",
    "                            \"title\": title  # Filter by title\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # Combine the KNN and keyword search queries\n",
    "            search_query = {\n",
    "                \"knn\": knn_query,\n",
    "                \"query\": keyword_query,\n",
    "                \"size\": num_results,  # Limit the number of results\n",
    "                \"_source\": [\"answer\", \"section\", \"question\", \"title\"]\n",
    "            }\n",
    "\n",
    "            # Perform the search\n",
    "            es_results = self.es.search(index=self.index_name, body=search_query)\n",
    "            result_docs = []\n",
    "\n",
    "            # Collect results\n",
    "            for hit in es_results['hits']['hits']:\n",
    "                result_docs.append(hit['_source'])  # Append only the source of each document\n",
    "\n",
    "            return result_docs\n",
    "\n",
    "        \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing KNN and keyword search: {e}\")\n",
    "            return []\n",
    "\n",
    "    \n",
    "    def compute_rrf(self, rank, k=60):\n",
    "        \"\"\"Compute Reciprocal Rank Fusion (RRF) score.\"\"\"\n",
    "        return 1 / (k + rank)\n",
    "\n",
    "    \n",
    "    def read_reviews_knn_and_keyword_rrf(self, field, query, vector, title, k=60, num_results=5):\n",
    "        \"\"\"Retrieve reviews using both KNN and keyword search, applying RRF for fusion.\"\"\"\n",
    "        try:\n",
    "            # Ensure the model is set\n",
    "            if self.model is None:\n",
    "                raise ValueError(\"Model for embedding generation is not initialized.\")\n",
    "\n",
    "            # Define the KNN query\n",
    "            knn_query = {\n",
    "                \"field\": field,  # Use the specified vector field (e.g., \"answer_vector\")\n",
    "                \"query_vector\": vector,\n",
    "                \"k\": num_results,\n",
    "                \"num_candidates\": 10000,\n",
    "                \"boost\": 0.5,\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"title\": title  # Filter by title\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # Define the keyword search query\n",
    "            keyword_query = {\n",
    "                \"bool\": {\n",
    "                    \"must\": {\n",
    "                        \"multi_match\": {\n",
    "                            \"query\": query,\n",
    "                            \"fields\": [\"question\", \"answer\", \"section\"],\n",
    "                            \"type\": \"best_fields\",\n",
    "                            \"boost\": 0.5\n",
    "                        }\n",
    "                    },\n",
    "                    \"filter\": {\n",
    "                        \"term\": {\n",
    "                            \"title\": title  # Filter by title\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # Execute the KNN search\n",
    "            knn_results = self.es.search(index=self.index_name, body={\"knn\": knn_query, \"size\": num_results})['hits']['hits']\n",
    "\n",
    "            # Execute the keyword search\n",
    "            keyword_results = self.es.search(index=self.index_name, body={\"query\": keyword_query, \"size\": num_results})['hits']['hits']\n",
    "\n",
    "            # Initialize the RRF score dictionary\n",
    "            rrf_scores = {}\n",
    "\n",
    "            # Calculate RRF for KNN results\n",
    "            for rank, hit in enumerate(knn_results):\n",
    "                doc_id = hit['_id']\n",
    "                rrf_scores[doc_id] = self.compute_rrf(rank + 1, k)\n",
    "                print(f\"KNN: Doc {doc_id} rank {rank + 1}, RRF score: {rrf_scores[doc_id]}\")\n",
    "\n",
    "            # Calculate RRF for Keyword results\n",
    "            for rank, hit in enumerate(keyword_results):\n",
    "                doc_id = hit['_id']\n",
    "                if doc_id in rrf_scores:\n",
    "                    rrf_scores[doc_id] += self.compute_rrf(rank + 1, k)\n",
    "                else:\n",
    "                    rrf_scores[doc_id] = self.compute_rrf(rank + 1, k)\n",
    "                print(f\"Keyword: Doc {doc_id} rank {rank + 1}, RRF score: {rrf_scores[doc_id]}\")\n",
    "\n",
    "            # Sort documents based on the RRF scores\n",
    "            reranked_docs = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "            # Get the top K documents by RRF scores\n",
    "            final_results = []\n",
    "            for doc_id, score in reranked_docs[:num_results]:\n",
    "                doc = self.es.get(index=self.index_name, id=doc_id)\n",
    "                final_results.append(doc['_source'])\n",
    "\n",
    "            return final_results\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing KNN and keyword search with RRF: {e}\")\n",
    "            return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb6c323-6baa-4787-89ed-b00a5622514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "\n",
    "# Initialize the SentenceTransformer model for embedding generation\n",
    "model_name = 'multi-qa-MiniLM-L6-cos-v1'\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# Create a reader instance with the model\n",
    "reader = ReviewReader(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3671b5a1-8530-48ab-8460-2c8703a26e3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example of reading all indexed reviews\n",
    "all_reviews = reader.read_all_reviews()\n",
    "print(\"All Indexed Reviews:\")\n",
    "for review in all_reviews:\n",
    "    print(review['_id'])  # Print the id of each review\n",
    "    # print(review['_source'])  # Print the source of each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81520886-3a5c-46e3-a8a1-500d405e5d87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example of reading specific review by appid\n",
    "specific_reviews = reader.read_review_by_appid(\"2322010\")\n",
    "print(\"\\nSpecific Reviews for appid 2322010  :\")\n",
    "for review in specific_reviews:\n",
    "    print(\"-\" * 79)\n",
    "    print(review['_id'])  # Print the source of the specific review\n",
    "    print(review['_source'])  # Print the source of the specific review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23016ce8-0ded-4a51-8f43-0e981a79163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = [\n",
    "    {\n",
    "        'title': 'God of War: Ragnarok',\n",
    "        'question': \"Is this game for kids?\"\n",
    "    },\n",
    "    {\n",
    "        'title': 'Far Cry 5',\n",
    "        'question': \"Is this game open world with outpost capture mechanics?\"\n",
    "    },\n",
    "    # Add more ground truth examples as needed\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dc6810-3ef9-4a44-bff1-7f8ddca97907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hit_rate(relevance_total):\n",
    "#     cnt = 0\n",
    "#     print(\"cnt:\", cnt)\n",
    "\n",
    "#     for line in relevance_total:\n",
    "#         if True in line:\n",
    "#             cnt = cnt + 1\n",
    "\n",
    "#     print(\"cnt:\", cnt)\n",
    "\n",
    "#     return cnt / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e69f85-276b-4a79-98e7-726d75d1e5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    # Count the total number of True values\n",
    "    total_true_count = sum(sum(line) for line in relevance_total)\n",
    "\n",
    "    # Calculate the hit rate (percentage of True values over total values)\n",
    "    total_values = sum(len(line) for line in relevance_total)  # total number of elements\n",
    "    hit_rate_value = total_true_count / total_values if total_values > 0 else 0.0\n",
    "\n",
    "    print(\"Total count of True values:\", total_true_count)\n",
    "    print(\"Hit Rate:\", hit_rate_value)\n",
    "\n",
    "    return hit_rate_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33e7d3e-daa4-4b77-98df-f5d42229f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2affeb08-6cc6-47a6-bd18-561b9b4dc4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "    total_documents = 0  # To count all documents\n",
    "    num_lines = len(relevance_total)\n",
    "\n",
    "    # Calculate the total score by summing the reciprocal ranks of True values\n",
    "    for line_index, line in enumerate(relevance_total):\n",
    "        line_score = 0.0  # Score for the current line\n",
    "        for rank, is_relevant in enumerate(line):\n",
    "            total_documents += 1  # Count each document\n",
    "            if is_relevant:\n",
    "                line_score += 1 / (rank + 1)  # Add the reciprocal rank\n",
    "                print(f\"Line {line_index + 1}: Found relevant at rank {rank + 1}, score added: {1 / (rank + 1)}\")\n",
    "            else:\n",
    "                print(f\"Line {line_index + 1}: Found irrelevant at rank {rank + 1}\")\n",
    "\n",
    "        # If there's a relevant item in the line, accumulate the score\n",
    "        if line_score > 0:\n",
    "            total_score += line_score\n",
    "            print(f\"Line {line_index + 1}: Total line score: {line_score}\")\n",
    "\n",
    "    # Calculate the mean reciprocal rank using total_documents\n",
    "    mean_reciprocal_rank = total_score / total_documents if total_documents > 0 else 0.0\n",
    "    print(f\"Total Score: {total_score}, Total Documents: {total_documents}, Mean Reciprocal Rank: {mean_reciprocal_rank}\")\n",
    "\n",
    "    return mean_reciprocal_rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c403b64-6d57-48c8-b140-d7c34df0e938",
   "metadata": {},
   "outputs": [],
   "source": [
    "field='question_answer_vector'\n",
    "question=\"Is God of War launching with controller?\"\n",
    "title=\"God of War: Ragnarok\"\n",
    "# title=\"Far Cry 5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6293fe0-86e0-460f-b15a-ee41005755a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_q = model.encode(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed617f35-99a9-4f1f-88a9-51ee13a58510",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = reader.read_reviews_knn_and_keyword(field=field, query=question, vector=v_q, title=title, num_results=5)\n",
    "# response = reader.read_reviews_knn_and_keyword(field=field, query=question, vector=v_q, num_results=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79e8061-0127-4cac-8831-830371b66513",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ff94eb-f5e8-497c-a158-2586cca8d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_text_hybrid(q):\n",
    "    field='question_answer_vector'\n",
    "    # question=\"Is God of War launching with proper controller support?\"\n",
    "    # title=\"God of War: Ragnarok\"\n",
    "    question = q['question']\n",
    "    title = q['title']\n",
    "    \n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return reader.read_reviews_knn_and_keyword(field=field, query=question, title=title, vector=v_q, num_results=10)\n",
    "    # return reader.read_reviews_knn_and_keyword(field=field, query=question, vector=v_q, num_results=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4707d1f0-7c1d-4a74-983d-995327865591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        print(\"q:\\n\", q)\n",
    "        \n",
    "        doc_id = q['title']\n",
    "        print(\"doc_id:\\n\", doc_id)\n",
    "        \n",
    "        results = search_function(q)\n",
    "        print(\"results:\\n\", results[0][\"answer\"])\n",
    "        \n",
    "        relevance = [d['title'] == doc_id for d in results]\n",
    "        print(\"relevance:\\n\", relevance)\n",
    "        \n",
    "        relevance_total.append(relevance)\n",
    "        print(\"relevance_total:\\n\", relevance_total)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fae0bd-b235-4767-98b5-6bc0f632b8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_sample = [\n",
    "    {\n",
    "        \"title\": \"God of War: Ragnarok\",\n",
    "        \"question\": \"Is the game worth the price if it's performance in considered?\"\n",
    "    },\n",
    "    # Add more ground truth examples as needed\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf000e5-0ab7-4932-8a51-9a328f93f8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(ground_truth=ground_truth_sample, search_function=question_text_hybrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835158c7-206b-407e-b208-6930e56f35ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbb4bb2-4df6-460d-803b-4528bf8271ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_text_hybrid_rrf(q):\n",
    "    field='question_answer_vector'\n",
    "    question = q['question']\n",
    "    title = q['title']\n",
    "    \n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return reader.read_reviews_knn_and_keyword_rrf(field=field, query=question, title=title, vector=v_q, num_results=10)\n",
    "    # return reader.read_reviews_knn_and_keyword(field=field, query=question, vector=v_q, num_results=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d6ca3b-15ae-484e-92ba-be5a5ed1c72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(ground_truth=ground_truth_sample, search_function=question_text_hybrid_rrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fe706d-2443-4774-80a7-eff026581d41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d00e94-a343-448f-af09-8ffa9c04e10f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c6969c-f58a-4f7e-85a5-b4ebc1f7fad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca035be0-16cc-44ff-b10f-8f3871b0d7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8f831e-17d1-4644-b224-15d86058fcbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8df1931-474d-447a-aaa1-5d53b471102d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde56ed7-ee85-419a-938d-51a02560775b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58c5729-834a-4eba-b048-6d7b5935e5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7933fe18-7561-42ae-b836-c558c464645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=os.environ['OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19e29c4-5224-4092-997e-1954244f37d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    answer_llm = \"\"\n",
    "\n",
    "    if 'entry_template' in globals():  # Check if entry_template exists in global scope\n",
    "        for doc in search_results:\n",
    "            answer_llm += entry_template.format(**doc) + \"\\n\\n\"\n",
    "    else:\n",
    "        for doc in search_results:\n",
    "            # Fallback formatting if entry_template is missing\n",
    "            answer_llm += str(doc) + \"\\n\\n\"\n",
    "\n",
    "    prompt = prompt_template.format(question=query, answer_llm=answer_llm).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eefa6f-8176-4b80-9a6f-e24f4463fa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt, model='gpt-4o-mini'):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fdac07-f37d-482e-8571-555e62cddf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query, model='gpt-4o-mini'):\n",
    "    # search_results = search(query)\n",
    "    search_results = reader.read_reviews_knn_and_keyword(field=field, query=question, title=title, vector=v_q, num_results=5)\n",
    "    print(search_results)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    #print(prompt)\n",
    "    answer = llm(prompt, model=model)\n",
    "    # print(answer)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df13f381-40c2-4909-93be-e945f84a187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an expert evaluator for a RAG system.\n",
    "Your task is to analyze the relevance of the generated answer to the given question.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the question\n",
    "and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb1aca5-d294-4f78-900d-de204347616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bfc245-bd74-4541-b612-366a63972d2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    answer_llm = \"\"\n",
    "\n",
    "    if 'entry_template' in globals():  # Check if entry_template exists in global scope\n",
    "        for doc in search_results:\n",
    "            answer_llm += entry_template.format(**doc) + \"\\n\\n\"\n",
    "    else:\n",
    "        for doc in search_results:\n",
    "            # Fallback formatting if entry_template is missing\n",
    "            answer_llm += str(doc) + \"\\n\\n\"\n",
    "\n",
    "    prompt = prompt_template.format(question=query, answer_llm=answer_llm).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm(prompt, model='gpt-4o-mini'):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def rag(query, model='gpt-4o-mini'):\n",
    "    # search_results = search(query)\n",
    "    search_results = reader.read_reviews_knn_and_keyword(field=field, query=query, title=title, vector=v_q, num_results=5)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt, model=model)\n",
    "    \n",
    "    # Return both the query and the answer\n",
    "    return query, answer\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "evaluations = []\n",
    "\n",
    "for record in tqdm(ground_truth):\n",
    "    question = record['question']\n",
    "    \n",
    "    # Get LLM answer and the question\n",
    "    query, answer_llm = rag(question)\n",
    "\n",
    "    # Format the prompt with the question and LLM answer\n",
    "    prompt = prompt_template.format(\n",
    "        question=query,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    # Get evaluation from LLM\n",
    "    evaluation = llm(prompt)\n",
    "    evaluation = json.loads(evaluation)\n",
    "\n",
    "    # Append a dictionary with record and evaluation details\n",
    "    evaluations.append({\n",
    "        \"record\": record,\n",
    "        \"evaluation\": {\n",
    "            \"query\": query,\n",
    "            \"answer_llm\": answer_llm,\n",
    "            \"evaluation\": evaluation\n",
    "        }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cfe3d5-ff1a-4afa-a70b-872d581b8e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ab3121-b105-4730-9600-17a0966c2391",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations[0]['record']['document_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb8bb43-f962-4921-9dc2-12a2a036d389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save the JSON file\n",
    "data_dir = os.path.abspath('../reviews-assistant/data/ground_truth')\n",
    "\n",
    "# Define the output file path\n",
    "output_file = os.path.join(data_dir, \"ground_truth_evaluation.json\")\n",
    "\n",
    "# Save evaluations as JSON\n",
    "with open(output_file, 'w') as file:\n",
    "    json.dump(evaluations, file, indent=4)\n",
    "\n",
    "print(f\"Data has been saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd829dd-349c-4847-af26-661efb7ff15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Assume `evaluations` is a list of dictionaries containing the evaluation data\n",
    "# Example: evaluations = [ {...}, {...}, ..., {...} ]\n",
    "# Load your evaluations JSON from file or it might already be defined in your script.\n",
    "# If it's in a JSON file, you can load it as follows:\n",
    "# with open('path_to_your_evaluations.json', 'r') as file:\n",
    "#     evaluations = json.load(file)\n",
    "\n",
    "# Assuming evaluations is already available as a list of dictionaries:\n",
    "# Initialize an empty list to hold the records for the DataFrame\n",
    "records = []\n",
    "\n",
    "# Iterate through each evaluation entry\n",
    "for evaluation in evaluations:\n",
    "    record = evaluation['record']  # Extract the record part\n",
    "    eval_info = evaluation['evaluation']  # Extract the evaluation part\n",
    "\n",
    "    # Append a dictionary with the necessary data\n",
    "    records.append({\n",
    "        \"document_id\": record['document_id'],\n",
    "        \"appid\": record['appid'],\n",
    "        \"title\": record['review']['title'],\n",
    "        \"review\": record['review']['review'],\n",
    "        \"voted_up\": record['review']['voted_up'],\n",
    "        \"votes_up\": record['review']['votes_up'],\n",
    "        \"timestamp_query\": record['review']['timestamp_query'],\n",
    "        \"question\": record['question'],\n",
    "        \"answer\": record['answer'],\n",
    "        \"section\": record['section'],\n",
    "        \"evaluation_query\": eval_info['query'],\n",
    "        # \"evaluation_answer_llm\": json.loads(eval_info['answer_llm']),  # Parse the answer_llm JSON string\n",
    "        \"evaluation_relevance\": eval_info['evaluation']['relevance'],\n",
    "        \"evaluation_explanation\": eval_info['evaluation']['explanation'],\n",
    "    })\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Display the DataFrame\n",
    "# print(df.head())  # Print the first few rows of the DataFrame for verification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbfd1a9-3173-4811-a4b1-d9fdae8bc2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73d8522-6ebb-4797-bb0f-42e63951facc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_eval = pd.DataFrame(evaluations, columns=['question', 'record', 'answer', 'evaluation'])\n",
    "\n",
    "# df_eval['appid'] = df_eval.record.apply(lambda d: d['appid'])\n",
    "# df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "# df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['relevance'])\n",
    "# df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['explanation'])\n",
    "\n",
    "# del df_eval['record']\n",
    "# del df_eval['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61400459-6263-4fbb-a6f3-9f94c24e4013",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.evaluation_relevance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffef4af-cb8c-4c26-a691-df2876cb1daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.evaluation_relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac1615e-cba1-4b62-8276-0778d7989454",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"evaluation_relevance\"]==\"RELEVANT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456699e2-aed6-4c0d-8a4f-5b7aed1ae0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"evaluation_relevance\"]==\"NON_RELEVANT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef54e657-8b48-469f-95b7-c0aef03ce6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"appid\"]==\"2322010\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc582374-1b58-4de0-819a-5cc87b1e9fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
